{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modules loaded\n"
     ]
    }
   ],
   "source": [
    "# import system libs \n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import itertools\n",
    "\n",
    "# import data handling tools \n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "import matplotlib.pyplot as plt\n",
    "# import Deep learning Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adam, Adamax\n",
    "from keras import regularizers\n",
    "from keras.metrics import categorical_crossentropy\n",
    "\n",
    "# Ignore Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print ('modules loaded')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10015, 2353)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = 'datasSet/hmnist_28_28_RGB.csv'\n",
    "data = pd.read_csv(data_dir)\n",
    "#data.head(20)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Label = data[\"label\"]\n",
    "Data = data.drop(columns=[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    6705\n",
       "6    1113\n",
       "2    1099\n",
       "1     514\n",
       "0     327\n",
       "5     142\n",
       "3     115\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"label\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Data : (46935, 28, 28, 3)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler \n",
    "\n",
    "oversample = RandomOverSampler()\n",
    "Data, Label  = oversample.fit_resample(Data, Label)\n",
    "Data = np.array(Data).reshape(-1, 28, 28, 3)\n",
    "print('Shape of Data :', Data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Label = np.array(Label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {4: ('nv', ' melanocytic nevi'),\n",
    "           6: ('mel', 'melanoma'),\n",
    "           2 :('bkl', 'benign keratosis-like lesions'), \n",
    "           1:('bcc' , ' basal cell carcinoma'),\n",
    "           5: ('vasc', ' pyogenic granulomas and hemorrhage'),\n",
    "           0: ('akiec', 'Actinic keratoses and intraepithelial carcinomae'),\n",
    "           3: ('df', 'dermatofibroma')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_full , X_test , y_train_full , y_test = train_test_split(Data , Label , test_size = 0.25 , random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_train_full = to_categorical(y_train_full)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "\n",
    "X_valid,X_train=X_train_full[:2500]/255.,X_train_full[2500:]/255.\n",
    "y_valid,y_train=y_train_full[:2500],y_train_full[2500:]\n",
    "\n",
    "X_test=X_test/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy'\n",
    "                                            , patience = 2\n",
    "                                            , verbose=1\n",
    "                                            ,factor=0.5\n",
    "                                            , min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 14, 14, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 14, 14, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 7, 7, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 7, 7, 128)         73856     \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 7, 7, 128)         147584    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 3, 3, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 3, 3, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 3, 3, 256)         295168    \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 3, 3, 256)         590080    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 1, 1, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               65792     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " classifier (Dense)          (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,275,079\n",
      "Trainable params: 1,273,671\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "# Create Model Structure\n",
    "model.add(keras.layers.Input(shape=[28, 28, 3]))\n",
    "model.add(keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal'))\n",
    "model.add(keras.layers.MaxPooling2D())\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal'))\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal'))\n",
    "model.add(keras.layers.MaxPooling2D())\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal'))\n",
    "model.add(keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal'))\n",
    "model.add(keras.layers.MaxPooling2D())\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal'))\n",
    "model.add(keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal'))\n",
    "model.add(keras.layers.MaxPooling2D())\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dropout(rate=0.2))\n",
    "model.add(keras.layers.Dense(units=256, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Dense(units=128, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Dense(units=64, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Dense(units=32, activation='relu', kernel_initializer='he_normal', kernel_regularizer=keras.regularizers.L1L2()))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Dense(units=7, activation='softmax', kernel_initializer='glorot_uniform', name='classifier'))\n",
    "model.compile(Adamax(learning_rate= 0.001), loss= 'categorical_crossentropy', metrics= ['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "256/256 [==============================] - 76s 287ms/step - loss: 1.1947 - accuracy: 0.5704 - val_loss: 2.3648 - val_accuracy: 0.2560 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "256/256 [==============================] - 74s 290ms/step - loss: 0.5023 - accuracy: 0.8355 - val_loss: 0.5625 - val_accuracy: 0.7920 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "256/256 [==============================] - 305s 1s/step - loss: 0.2983 - accuracy: 0.9006 - val_loss: 0.3016 - val_accuracy: 0.8936 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "256/256 [==============================] - 74s 291ms/step - loss: 0.2068 - accuracy: 0.9297 - val_loss: 0.2297 - val_accuracy: 0.9116 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "256/256 [==============================] - 89s 347ms/step - loss: 0.1502 - accuracy: 0.9491 - val_loss: 0.1681 - val_accuracy: 0.9428 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "256/256 [==============================] - 92s 360ms/step - loss: 0.1122 - accuracy: 0.9628 - val_loss: 0.1623 - val_accuracy: 0.9456 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "256/256 [==============================] - 79s 309ms/step - loss: 0.0892 - accuracy: 0.9698 - val_loss: 0.1159 - val_accuracy: 0.9632 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "256/256 [==============================] - 72s 281ms/step - loss: 0.0743 - accuracy: 0.9746 - val_loss: 0.1927 - val_accuracy: 0.9368 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 0.0633 - accuracy: 0.9791\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "256/256 [==============================] - 78s 304ms/step - loss: 0.0633 - accuracy: 0.9791 - val_loss: 0.1359 - val_accuracy: 0.9572 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "256/256 [==============================] - 80s 311ms/step - loss: 0.0250 - accuracy: 0.9927 - val_loss: 0.0791 - val_accuracy: 0.9756 - lr: 5.0000e-04\n",
      "Epoch 11/30\n",
      "256/256 [==============================] - 83s 324ms/step - loss: 0.0125 - accuracy: 0.9968 - val_loss: 0.0648 - val_accuracy: 0.9804 - lr: 5.0000e-04\n",
      "Epoch 12/30\n",
      "256/256 [==============================] - 83s 323ms/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.0590 - val_accuracy: 0.9816 - lr: 5.0000e-04\n",
      "Epoch 13/30\n",
      "256/256 [==============================] - 75s 294ms/step - loss: 0.0112 - accuracy: 0.9972 - val_loss: 0.0960 - val_accuracy: 0.9756 - lr: 5.0000e-04\n",
      "Epoch 14/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9974\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "256/256 [==============================] - 77s 300ms/step - loss: 0.0093 - accuracy: 0.9974 - val_loss: 0.1109 - val_accuracy: 0.9740 - lr: 5.0000e-04\n",
      "Epoch 15/30\n",
      "256/256 [==============================] - 81s 314ms/step - loss: 0.0051 - accuracy: 0.9989 - val_loss: 0.0784 - val_accuracy: 0.9816 - lr: 2.5000e-04\n",
      "Epoch 16/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9994\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "256/256 [==============================] - 84s 329ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.0767 - val_accuracy: 0.9816 - lr: 2.5000e-04\n",
      "Epoch 17/30\n",
      "256/256 [==============================] - 78s 306ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.0733 - val_accuracy: 0.9812 - lr: 1.2500e-04\n",
      "Epoch 18/30\n",
      "256/256 [==============================] - 80s 311ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.0692 - val_accuracy: 0.9828 - lr: 1.2500e-04\n",
      "Epoch 19/30\n",
      "256/256 [==============================] - 83s 325ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.0785 - val_accuracy: 0.9824 - lr: 1.2500e-04\n",
      "Epoch 20/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9999\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "256/256 [==============================] - 90s 350ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0791 - val_accuracy: 0.9824 - lr: 1.2500e-04\n",
      "Epoch 21/30\n",
      "256/256 [==============================] - 98s 381ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.0766 - val_accuracy: 0.9820 - lr: 6.2500e-05\n",
      "Epoch 22/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9998\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "256/256 [==============================] - 83s 325ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0712 - val_accuracy: 0.9828 - lr: 6.2500e-05\n",
      "Epoch 23/30\n",
      "256/256 [==============================] - 84s 329ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0760 - val_accuracy: 0.9828 - lr: 3.1250e-05\n",
      "Epoch 24/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 0.9999\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "256/256 [==============================] - 77s 301ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0794 - val_accuracy: 0.9812 - lr: 3.1250e-05\n",
      "Epoch 25/30\n",
      "256/256 [==============================] - 75s 293ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.0773 - val_accuracy: 0.9816 - lr: 1.5625e-05\n",
      "Epoch 26/30\n",
      "256/256 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9998\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "256/256 [==============================] - 76s 297ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0793 - val_accuracy: 0.9816 - lr: 1.5625e-05\n",
      "Epoch 27/30\n",
      "256/256 [==============================] - 92s 361ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0788 - val_accuracy: 0.9816 - lr: 1.0000e-05\n",
      "Epoch 28/30\n",
      "256/256 [==============================] - 85s 331ms/step - loss: 9.7459e-04 - accuracy: 1.0000 - val_loss: 0.0782 - val_accuracy: 0.9816 - lr: 1.0000e-05\n",
      "Epoch 29/30\n",
      "256/256 [==============================] - 84s 329ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0776 - val_accuracy: 0.9816 - lr: 1.0000e-05\n",
      "Epoch 30/30\n",
      "256/256 [==============================] - 82s 320ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.0789 - val_accuracy: 0.9816 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=30,\n",
    "    batch_size=128,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[learning_rate_reduction]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training(hist):\n",
    "    tr_acc = hist.history['accuracy']\n",
    "    tr_loss = hist.history['loss']\n",
    "    val_acc = hist.history['val_accuracy']\n",
    "    val_loss = hist.history['val_loss']\n",
    "    index_loss = np.argmin(val_loss)\n",
    "    val_lowest = val_loss[index_loss]\n",
    "    index_acc = np.argmax(val_acc)\n",
    "    acc_highest = val_acc[index_acc]\n",
    "\n",
    "    plt.figure(figsize= (20, 8))\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    Epochs = [i+1 for i in range(len(tr_acc))]\n",
    "    loss_label = f'best epoch= {str(index_loss + 1)}'\n",
    "    acc_label = f'best epoch= {str(index_acc + 1)}'\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\n",
    "    plt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\n",
    "    plt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\n",
    "    plt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\n",
    "    plt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = model.evaluate(X_train, y_train, verbose= 1)\n",
    "test_score = model.evaluate(X_test, y_test, verbose= 1)\n",
    "\n",
    "print(\"Train Loss: \", train_score[0])\n",
    "print(\"Train Accuracy: \", train_score[1])\n",
    "print('-' * 20)\n",
    "print(\"Test Loss: \", test_score[0])\n",
    "print(\"Test Accuracy: \", test_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = cm = confusion_matrix(y_true, y_pred, labels=classes_labels)\n",
    "\n",
    "plt.figure(figsize= (10, 10))\n",
    "plt.imshow(cm, interpolation= 'nearest', cmap= plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation= 45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "\n",
    "thresh = cm.max() / 2.\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, cm[i, j], horizontalalignment= 'center', color= 'white' if cm[i, j] > thresh else 'black')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model\n",
    "model.save('version0.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
